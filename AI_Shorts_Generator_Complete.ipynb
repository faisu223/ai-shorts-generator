{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎬 AI Shorts Generator - Complete Edition\n",
    "\n",
    "Generate AI-powered short clips from long videos with both CLI and Gradio interfaces.\n",
    "\n",
    "**⚠️ IMPORTANT: Run Setup Cells First!**\n",
    "Before importing any libraries, you **MUST** run the setup cells below to install all required dependencies. If you skip this step, you'll get import errors like \"ModuleNotFoundError: No module named 'pytubefix'\".\n",
    "\n",
    "**Setup Steps:**\n",
    "1. Run the \"🚀 Setup: System Dependencies & Python Packages\" cell\n",
    "2. Run the \"📦 Import Required Libraries\" cell\n",
    "3. Then proceed with the rest of the notebook\n",
    "\n",
    "**Features:**\n",
    "- ✅ Upload videos or use YouTube URLs\n",
    "- ✅ Optional SRT subtitle upload\n",
    "- ✅ AI-powered highlight detection (OpenAI/Gemini)\n",
    "- ✅ Automatic title generation\n",
    "- ✅ Multiple aspect ratios (9:16, 16:9, 1:1)\n",
    "- ✅ Face tracking or center crop modes\n",
    "- ✅ Karaoke-style subtitle burning\n",
    "- ✅ Watermark/logo overlay\n",
    "- ✅ Batch processing\n",
    "- ✅ Both CLI and GUI interfaces\n",
    "\n",
    "**Run in:** Google Colab (recommended) or local Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Setup: System Dependencies & Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies (for Colab)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg imagemagick fonts-freefont-ttf > /dev/null\n",
    "!sed -i 's/<policy domain=\"path\" rights=\"none\" pattern=\"@\\*\" \\/>/<\\!-- <policy domain=\"path\" rights=\"none\" pattern=\"@\\*\" \\/> --\\>/g' /etc/ImageMagick-6/policy.xml || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages\n",
    "!pip install --upgrade pip wheel setuptools\n",
    "!pip install gradio==4.* moviepy==2.2.1 imageio-ffmpeg\n",
    "!pip install numpy<2.0 opencv-python-headless pytubefix pydub pysrt\n",
    "!pip install faster-whisper google-generativeai 'openai>=1.35.0'\n",
    "\n",
    "print(\"✅ All dependencies installed successfully!\")\n",
    "print(\"📦 Key packages installed:\")\n",
    "print(\"  - pytubefix: YouTube video downloading\")\n",
    "print(\"  - moviepy: Video processing and editing\")\n",
    "print(\"  - faster-whisper: AI transcription\")\n",
    "print(\"  - gradio: Web interface\")\n",
    "print(\"  - openai & google-generativeai: AI services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU support (Colab only)\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    import os\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    print(\"✅ GPU support enabled\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, sys\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# Video processing\n",
    "try:\n",
    "    from moviepy import VideoFileClip, TextClip, CompositeVideoClip, ImageClip\n",
    "    from moviepy.video.fx import Crop as mp_crop\n",
    "    print(\"✅ MoviePy imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ MoviePy import failed: {e}\")\n",
    "    print(\"Please run the installation cell above first!\")\n",
    "\n",
    "# YouTube downloading\n",
    "try:\n",
    "    from pytubefix import YouTube\n",
    "    print(\"✅ PyTubeFix imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ PyTubeFix import failed: {e}\")\n",
    "    print(\"Please run the installation cell above first!\")\n",
    "\n",
    "# Audio processing\n",
    "try:\n",
    "    from faster_whisper import WhisperModel\n",
    "    print(\"✅ FasterWhisper imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ FasterWhisper import failed: {e}\")\n",
    "    print(\"Please run the installation cell above first!\")\n",
    "\n",
    "# AI services\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    import google.generativeai as genai\n",
    "    print(\"✅ AI services imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ AI services import failed: {e}\")\n",
    "    print(\"Please run the installation cell above first!\")\n",
    "\n",
    "# Utilities\n",
    "try:\n",
    "    import cv2\n",
    "    import gradio as gr\n",
    "    print(\"✅ Utilities imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Utilities import failed: {e}\")\n",
    "    print(\"Please run the installation cell above first!\")\n",
    "\n",
    "print(\"\\n🎯 All imports completed! Ready to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRT/Subtitle utilities\n",
    "def parse_srt_segments(path: str) -> List[Dict]:\n",
    "    \"\"\"Parse SRT file and return segments with timing\"\"\"\n",
    "    import re\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    blocks = re.split(r'\\n\\s*\\n', content.strip())\n",
    "    segs: List[Dict] = []\n",
    "    \n",
    "    for b in blocks:\n",
    "        lines = [l.strip('\\ufeff ') for l in b.splitlines() if l.strip()]\n",
    "        if not lines: continue\n",
    "        \n",
    "        time_line = None\n",
    "        for l in lines:\n",
    "            if '-->' in l:\n",
    "                time_line = l\n",
    "                break\n",
    "        if not time_line: continue\n",
    "        \n",
    "        try:\n",
    "            t0, t1 = [x.strip() for x in time_line.split('-->')]\n",
    "            def to_s(ts: str) -> float:\n",
    "                h, m, rest = ts.split(':')\n",
    "                s, ms = (rest + ',0').split(',')[:2]\n",
    "                return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000\n",
    "            st, et = to_s(t0), to_s(t1)\n",
    "            if et > st:\n",
    "                text = ' '.join([l for l in lines if l != time_line and not l.isdigit()])\n",
    "                segs.append({'start': st, 'end': et, 'text': text})\n",
    "        except Exception:\n",
    "            pass\n",
    "    return segs\n",
    "\n",
    "def segs_to_text(segs: List[Dict]) -> str:\n",
    "    \"\"\"Convert segments to continuous text\"\"\"\n",
    "    return ' '.join(s.get('text', '').strip() for s in segs)\n",
    "\n",
    "def words_from_segs(segs: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Extract words with timing from segments\"\"\"\n",
    "    import re\n",
    "    out: List[Dict] = []\n",
    "    for s in segs:\n",
    "        if s.get('words'):\n",
    "            out.append(s)\n",
    "            continue\n",
    "        text = s.get('text', '').strip()\n",
    "        words = re.findall(r\"\\w+['’-]?\\w*|\\S\", text)\n",
    "        dur = max(0.001, s['end'] - s['start'])\n",
    "        n = max(1, len(words))\n",
    "        step = dur / n\n",
    "        wlist = []\n",
    "        for i, w in enumerate(words):\n",
    "            ws = s['start'] + i*step\n",
    "            we = min(s['end'], ws + step)\n",
    "            wlist.append({'start': ws, 'end': we, 'text': w})\n",
    "        s2 = dict(s)\n",
    "        s2['words'] = wlist\n",
    "        out.append(s2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video processing utilities\n",
    "def aspect_tuple(s: str) -> Tuple[int, int]:\n",
    "    \"\"\"Convert aspect ratio string to tuple\"\"\"\n",
    "    a, b = s.split(':')\n",
    "    return int(a), int(b)\n",
    "\n",
    "def compute_center_crop(w: int, h: int, ratio: str) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"Calculate center crop dimensions\"\"\"\n",
    "    aw, ah = aspect_tuple(ratio)\n",
    "    tr = aw / ah\n",
    "    sr = w / h\n",
    "    if sr > tr:\n",
    "        cw = int(h * tr)\n",
    "        ch = h\n",
    "        x = (w - cw) // 2\n",
    "        y = 0\n",
    "    else:\n",
    "        cw = w\n",
    "        ch = int(w / tr)\n",
    "        x = 0\n",
    "        y = (h - ch) // 2\n",
    "    return x, y, cw, ch\n",
    "\n",
    "def crop_center(v: VideoFileClip, ratio: str) -> VideoFileClip:\n",
    "    \"\"\"Apply center crop to video\"\"\"\n",
    "    x, y, cw, ch = compute_center_crop(v.w, v.h, ratio)\n",
    "    return mp_crop(v, x1=x, y1=y, width=cw, height=ch).resize((cw, ch))\n",
    "\n",
    "# Face detection and tracking\n",
    "_HAAR: Optional[cv2.CascadeClassifier] = None\n",
    "\n",
    "def _load_haar():\n",
    "    \"\"\"Load Haar cascade classifier\"\"\"\n",
    "    global _HAAR\n",
    "    if _HAAR is None:\n",
    "        try:\n",
    "            candidates = []\n",
    "            haar_dir = getattr(cv2.data, 'haarcascades', '')\n",
    "            if haar_dir:\n",
    "                candidates.append(os.path.join(haar_dir, 'haarcascade_frontalface_default.xml'))\n",
    "            candidates.append('haarcascade_frontalface_default.xml')\n",
    "            candidates.append(os.path.join('models', 'haarcascade_frontalface_default.xml'))\n",
    "            path = next((p for p in candidates if os.path.exists(p)), '')\n",
    "            if path:\n",
    "                _HAAR = cv2.CascadeClassifier(path)\n",
    "            else:\n",
    "                _HAAR = None\n",
    "        except Exception:\n",
    "            _HAAR = None\n",
    "\n",
    "def detect_face(frame) -> Optional[Tuple[int, int, int, int]]:\n",
    "    \"\"\"Detect face in frame\"\"\"\n",
    "    _load_haar()\n",
    "    if _HAAR is None: return None\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    det = _HAAR.detectMultiScale(gray, 1.2, 3)\n",
    "    if len(det) == 0: return None\n",
    "    det = sorted(det, key=lambda d: d[2]*d[3], reverse=True)[0]\n",
    "    return int(det[0]), int(det[1]), int(det[2]), int(det[3])\n",
    "\n",
    "def crop_face_track(v: VideoFileClip, ratio: str, sample_fps: float = 4.0, smooth: float = 0.8) -> VideoFileClip:\n",
    "    \"\"\"Apply face tracking crop to video\"\"\"\n",
    "    aw, ah = aspect_tuple(ratio)\n",
    "    tr = aw / ah\n",
    "    w, h = v.w, v.h\n",
    "    sr = w / h\n",
    "    if sr > tr:\n",
    "        ch = h\n",
    "        cw = int(h * tr)\n",
    "    else:\n",
    "        cw = w\n",
    "        ch = int(w / tr)\n",
    "    duration = v.duration\n",
    "    times = np.arange(0, duration, 1.0/max(1.0, sample_fps))\n",
    "    path: List[Tuple[float, int, int]] = []\n",
    "    prev = None\n",
    "    for t in times:\n",
    "        try:\n",
    "            frame = v.get_frame(t)\n",
    "            b = detect_face(frame)\n",
    "            if b:\n",
    "                x, y, bw, bh = b\n",
    "                cx, cy = x + bw/2, y + bh/2\n",
    "            else:\n",
    "                cx, cy = prev if prev else (w/2, h/2)\n",
    "            if prev is None:\n",
    "                sx, sy = cx, cy\n",
    "            else:\n",
    "                sx = smooth*prev[0] + (1-smooth)*cx\n",
    "                sy = smooth*prev[1] + (1-smooth)*cy\n",
    "            prev = (sx, sy)\n",
    "            x1 = max(0, min(w - cw, int(sx - cw/2)))\n",
    "            y1 = max(0, min(h - ch, int(sy - ch/2)))\n",
    "            path.append((t, x1, y1))\n",
    "        except Exception:\n",
    "            continue\n",
    "    if not path:\n",
    "        return crop_center(v, ratio)\n",
    "    ts = [p[0] for p in path]\n",
    "    xs = [p[1] for p in path]\n",
    "    ys = [p[2] for p in path]\n",
    "\n",
    "    def interp(series: List[int]) -> callable:\n",
    "        def f(t: float) -> float:\n",
    "            if t <= ts[0]: return float(series[0])\n",
    "            if t >= ts[-1]: return float(series[-1])\n",
    "            i = max(0, np.searchsorted(ts, t) - 1)\n",
    "            t0, t1 = ts[i], ts[i+1]\n",
    "            v0, v1 = series[i], series[i+1]\n",
    "            if t1 == t0: return float(v1)\n",
    "            a = (t - t0) / (t1 - t0)\n",
    "            return float(v0*(1-a) + v1*a)\n",
    "        return f\n",
    "\n",
    "    fx = interp(xs)\n",
    "    fy = interp(ys)\n",
    "    return mp_crop(v, x1=lambda t: fx(t), y1=lambda t: fy(t), width=cw, height=ch).resize((cw, ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI-powered content analysis\n",
    "def pick_highlights(transcription: str, provider: str, api_key: str, max_clips: int, min_len: int, max_len: int) -> List[Dict]:\n",
    "    \"\"\"Use AI to identify highlight segments from transcription\"\"\"\n",
    "    import json\n",
    "    \n",
    "    sys = (\n",
    "        f\"You are an expert at finding viral video moments. Return up to {max_clips} segments between {min_len} and {max_len} seconds \"\n",
    "        \"as JSON array with keys start,end,content. Only return JSON. If none, return [].\"\n",
    "    )\n",
    "    \n",
    "    if provider == 'OpenAI':\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        r = client.chat.completions.create(\n",
    "            model='gpt-4o-mini', temperature=0.5,\n",
    "            messages=[{'role':'system','content':sys},{'role':'user','content':transcription}]\n",
    "        )\n",
    "        txt = r.choices[0].message.content\n",
    "    else:\n",
    "        genai.configure(api_key=api_key)\n",
    "        m = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        txt = m.generate_content(sys + '\\n\\n' + transcription).text\n",
    "    \n",
    "    txt = (txt or '').strip().replace('```','').replace('json','').strip()\n",
    "    try:\n",
    "        arr = json.loads(txt) if txt else []\n",
    "    except Exception:\n",
    "        arr = []\n",
    "    \n",
    "    out = []\n",
    "    for h in arr:\n",
    "        try:\n",
    "            s = float(h.get('start', 0)); e = float(h.get('end', 0))\n",
    "            if e > s and min_len <= e - s <= max_len:\n",
    "                out.append({'start': s, 'end': e, 'content': h.get('content','')})\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def generate_titles_from_highlights(highs: List[Dict], provider: str, api_key: str) -> List[str]:\n",
    "    \"\"\"Generate titles for highlight segments using AI\"\"\"\n",
    "    import json\n",
    "    if not highs: return []\n",
    "    \n",
    "    prompt = 'Create ultra-short (<=40 chars), high-energy titles with emojis for these clip summaries. Return JSON array of strings only.\\n' + \\\n",
    "             json.dumps([h.get('content','') for h in highs])\n",
    "    \n",
    "    try:\n",
    "        if provider == 'OpenAI':\n",
    "            client = OpenAI(api_key=api_key)\n",
    "            r = client.chat.completions.create(model='gpt-4o-mini', temperature=0.7, messages=[{'role':'user','content':prompt}])\n",
    "            txt = r.choices[0].message.content\n",
    "        else:\n",
    "            genai.configure(api_key=api_key)\n",
    "            m = genai.GenerativeModel('gemini-2.5-flash')\n",
    "            txt = m.generate_content(prompt).text\n",
    "        \n",
    "        txt = (txt or '').strip().replace('```','').replace('json','').strip()\n",
    "        arr = json.loads(txt) if txt else []\n",
    "        return [str(a)[:60] for a in arr]\n",
    "    except Exception:\n",
    "        return [h.get('content','Clip')[:40] for h in highs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline functions\n",
    "def download_youtube(url: str) -> Optional[str]:\n",
    "    \"\"\"Download YouTube video and return path\"\"\"\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        stream = (yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first() or\n",
    "                  yt.streams.filter(file_extension='mp4').order_by('resolution').desc().first())\n",
    "        os.makedirs('videos', exist_ok=True)\n",
    "        return stream.download(output_path='videos')\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def transcribe(video_path: str, logger=print):\n",
    "    \"\"\"Transcribe video using Whisper\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        device = 'cuda' if getattr(torch, 'cuda', None) and torch.cuda.is_available() else 'cpu'\n",
    "    except Exception:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    model = WhisperModel('base.en', device=device, compute_type='float16' if device=='cuda' else 'int8')\n",
    "    seg_iter, _ = model.transcribe(video_path, beam_size=5, language='en', word_timestamps=True)\n",
    "    segs = []\n",
    "    for s in seg_iter:\n",
    "        words = []\n",
    "        if getattr(s, 'words', None):\n",
    "            for w in s.words:\n",
    "                words.append({'start': float(w.start), 'end': float(w.end), 'text': w.word})\n",
    "        segs.append({'start': float(s.start), 'end': float(s.end), 'text': s.text.strip(), 'words': words})\n",
    "    return segs, segs_to_text(segs)\n",
    "\n",
    "def add_title_overlay(video_path: str, out_path: str, title_text: str, platform: str = 'TikTok'):\n",
    "    \"\"\"Add title overlay to video\"\"\"\n",
    "    with VideoFileClip(video_path) as v:\n",
    "        w, h = v.w, v.h\n",
    "        margin = int(0.10*h if platform == 'TikTok' else 0.08*h)\n",
    "        txt = TextClip(title_text, font='FreeMono', fontsize=max(36, int(h*0.05)), color='white', stroke_color='black', stroke_width=2)\n",
    "        txt = txt.set_pos(('center', margin)).set_duration(v.duration)\n",
    "        CompositeVideoClip([v, txt]).write_videofile(out_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "def add_watermark(video_path: str, wm_path: str, out_path: str):\n",
    "    \"\"\"Add watermark to video\"\"\"\n",
    "    with VideoFileClip(video_path) as v:\n",
    "        wm = (ImageClip(wm_path).set_duration(v.duration).resize(height=int(max(48, v.h*0.06))).set_pos(('right','top')))\n",
    "        CompositeVideoClip([v, wm]).write_videofile(out_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "def write_ass_karaoke(segs: List[Dict], path: str, t0: float, t1: float, resolution: Tuple[int, int]):\n",
    "    \"\"\"Write ASS karaoke subtitle file\"\"\"\n",
    "    import re\n",
    "    W, H = resolution\n",
    "    header = (\n",
    "        \"[Script Info]\\n\"\n",
    "        \"ScriptType: v4.00+\\n\"\n",
    "        f\"PlayResX: {W}\\n\"\n",
    "        f\"PlayResY: {H}\\n\"\n",
    "        \"ScaledBorderAndShadow: yes\\n\\n\"\n",
    "        \"[V4+ Styles]\\n\"\n",
    "        \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\n\"\n",
    "        \"Style: Karaoke,Arial,60,&H00FFFFFF,&H0000FFFF,&H00000000,&H80000000,0,0,0,0,100,100,0,0,1,2,0,2,80,80,140,1\\n\\n\"\n",
    "        \"[Events]\\n\"\n",
    "        \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n\"\n",
    "    )\n",
    "    lines = [header]\n",
    "    for s in segs:\n",
    "        if s['end'] < t0 or s['start'] > t1: continue\n",
    "        a = max(t0, s['start'])\n",
    "        b = min(t1, s['end'])\n",
    "        words = [w for w in s.get('words', []) if not (w['end'] < a or w['start'] > b)]\n",
    "        if not words: continue\n",
    "        parts = []\n",
    "        for w in words:\n",
    "            ws = max(a, w['start'])\n",
    "            we = min(b, w['end'])\n",
    "            k = max(1, int((we - ws) * 100))\n",
    "            txt = re.sub(r'[{}\\\\\\\\]', '', w['text'])\n",
    "            parts.append(f\"{{\\\\k{k}}}{txt}\")\n",
    "        text = ''.join(parts)\n",
    "        lines.append(\n",
    "            f\"Dialogue: 0,{_ass_ts(a-t0)},{_ass_ts(b-t0)},Karaoke,,0000,0000,0000,,{text}\\n\"\n",
    "        )\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "def _ass_ts(t: float) -> str:\n",
    "    \"\"\"Convert time to ASS timestamp format\"\"\"\n",
    "    h = int(t // 3600)\n",
    "    m = int((t % 3600) // 60)\n",
    "    s = int(t % 60)\n",
    "    cs = int((t - int(t)) * 100)\n",
    "    return f\"{h:01d}:{m:02d}:{s:02d}.{cs:02d}\"\n",
    "\n",
    "def burn_ass_to_video(input_path: str, ass_path: str, output_path: str):\n",
    "    \"\"\"Burn ASS subtitles to video using ffmpeg\"\"\"\n",
    "    import subprocess, shlex\n",
    "    cmd = f\"ffmpeg -y -i {shlex.quote(input_path)} -vf subtitles={shlex.quote(ass_path)} -c:a aac -c:v libx264 -pix_fmt yuv420p {shlex.quote(output_path)}\"\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "def write_srt_for_range(segs: List[Dict], path: str, t0: float, t1: float):\n",
    "    \"\"\"Write SRT file for time range\"\"\"\n",
    "    def _srt_ts(t: float) -> str:\n",
    "        t = max(0.0, t)\n",
    "        h = int(t // 3600)\n",
    "        m = int((t % 3600) // 60)\n",
    "        s = int(t % 60)\n",
    "        ms = int(round((t - int(t)) * 1000))\n",
    "        return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
    "    \n",
    "    idx = 1\n",
    "    lines = []\n",
    "    for s in segs:\n",
    "        if s['end'] <= t0 or s['start'] >= t1: continue\n",
    "        a = max(t0, s['start'])\n",
    "        b = min(t1, s['end'])\n",
    "        text = s.get('text', '').strip()\n",
    "        if not text: continue\n",
    "        sa = _srt_ts(a - t0)\n",
    "        sb = _srt_ts(b - t0)\n",
    "        lines.append(f\"{idx}\\n{sa} --> {sb}\\n{text}\\n\\n\")\n",
    "        idx += 1\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline function\n",
    "def generate_pipeline(youtube_url, video_file, srt_file, provider, openai_key, gemini_key, \n",
    "                     min_len, max_len, max_clips, aspect, crop_mode, karaoke, export_srt, \n",
    "                     title_mode, custom_title, platform, out_prefix, watermark_file, \n",
    "                     seo_text='', logger=print):\n",
    "    \"\"\"Main pipeline to generate shorts from video\"\"\"\n",
    "    \n",
    "    # Get video path\n",
    "    path = None\n",
    "    if youtube_url:\n",
    "        path = download_youtube(youtube_url)\n",
    "        if path: logger(f\"Downloaded YouTube -> {path}\")\n",
    "    if not path and video_file is not None:\n",
    "        path = video_file.name\n",
    "    if not path:\n",
    "        logger('No video provided.')\n",
    "        return None\n",
    "\n",
    "    # Transcription\n",
    "    if srt_file is not None:\n",
    "        segs = parse_srt_segments(srt_file.name)\n",
    "        text = segs_to_text(segs)\n",
    "        segs = words_from_segs(segs)\n",
    "    else:\n",
    "        logger('Starting Whisper transcription...')\n",
    "        segs, text = transcribe(path, logger)\n",
    "    \n",
    "    if not text:\n",
    "        logger('Empty transcription')\n",
    "        return None\n",
    "\n",
    "    # AI highlight selection\n",
    "    api_key = openai_key if provider == 'OpenAI' else gemini_key\n",
    "    if not api_key:\n",
    "        logger(f\"Missing API key for {provider}. Please provide a valid key.\")\n",
    "        return None\n",
    "    \n",
    "    logger(f'Finding highlights using {provider}...')\n",
    "    highs = pick_highlights(text, provider, api_key, int(max_clips), int(min_len), int(max_len))\n",
    "    if not highs:\n",
    "        logger('No highlights found.')\n",
    "        return None\n",
    "\n",
    "    # Title generation\n",
    "    if title_mode == 'Auto':\n",
    "        logger('Generating titles...')\n",
    "        titles = generate_titles_from_highlights(highs, provider, api_key)\n",
    "    elif title_mode == 'Custom':\n",
    "        titles = [custom_title or ''] * len(highs)\n",
    "    else:\n",
    "        titles = [''] * len(highs)\n",
    "\n",
    "    out_pref = out_prefix or 'short'\n",
    "    outputs: List[str] = []\n",
    "    srt_outputs: List[str] = []\n",
    "\n",
    "    # Process each highlight\n",
    "    for i, h in enumerate(highs, start=1):\n",
    "        s, e = float(h['start']), float(h['end'])\n",
    "        clip_path = f\"{out_pref}_{i}.mp4\"\n",
    "        \n",
    "        with VideoFileClip(path) as v:\n",
    "            sub = v.subclip(s, e)\n",
    "            if crop_mode == 'Face-track':\n",
    "                sub = crop_face_track(sub, aspect)\n",
    "            else:\n",
    "                sub = crop_center(sub, aspect)\n",
    "            \n",
    "            logger(f\"Rendering clip {i}: {s:.2f}s to {e:.2f}s\")\n",
    "            sub.write_videofile(clip_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "        # Export per-clip SRT\n",
    "        if export_srt and segs:\n",
    "            try:\n",
    "                srt_path = f\"{out_pref}_{i}.srt\"\n",
    "                write_srt_for_range(segs, srt_path, s, e)\n",
    "                srt_outputs.append(srt_path)\n",
    "            except Exception as ex:\n",
    "                logger(f\"SRT export failed for clip {i}: {ex}\")\n",
    "\n",
    "        cur = clip_path\n",
    "        \n",
    "        # Add karaoke subtitles\n",
    "        if karaoke and segs:\n",
    "            ass = f\"{out_pref}_{i}.ass\"\n",
    "            res = (1080,1920) if aspect == '9:16' else (1920,1080)\n",
    "            write_ass_karaoke(segs, ass, s, e, res)\n",
    "            kara = f\"{out_pref}_{i}_karaoke.mp4\"\n",
    "            try:\n",
    "                burn_ass_to_video(cur, ass, kara)\n",
    "                cur = kara\n",
    "            except Exception as ex:\n",
    "                logger(f\"Karaoke burn failed: {ex}\")\n",
    "\n",
    "        # Add title overlay\n",
    "        ttl = titles[i-1] if i-1 < len(titles) else ''\n",
    "        if ttl:\n",
    "            ttl_out = f\"{out_pref}_{i}_title.mp4\"\n",
    "            try:\n",
    "                add_title_overlay(cur, ttl_out, ttl, platform)\n",
    "                cur = ttl_out\n",
    "            except Exception as ex:\n",
    "                logger(f\"Title overlay failed: {ex}\")\n",
    "\n",
    "        # Add watermark\n",
    "        if watermark_file is not None:\n",
    "            wm_out = f\"{out_pref}_{i}_wm.mp4\"\n",
    "            try:\n",
    "                add_watermark(cur, watermark_file.name, wm_out)\n",
    "                cur = wm_out\n",
    "            except Exception as ex:\n",
    "                logger(f\"Watermark failed: {ex}\")\n",
    "\n",
    "        outputs.append(cur)\n",
    "\n",
    "    # Write SEO/description if provided\n",
    "    if seo_text:\n",
    "        try:\n",
    "            with open(f\"{out_pref}_description.txt\", 'w', encoding='utf-8') as f:\n",
    "                f.write(seo_text.strip() + \"\\n\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Create ZIP file\n",
    "    zip_path = f\"{out_pref}_results.zip\"\n",
    "    with zipfile.ZipFile(zip_path, 'w') as z:\n",
    "        for f in outputs:\n",
    "            if os.path.exists(f):\n",
    "                z.write(f)\n",
    "        \n",
    "        for srt in srt_outputs:\n",
    "            if os.path.exists(srt):\n",
    "                z.write(srt)\n",
    "        \n",
    "        if export_srt and segs:\n",
    "            with open('transcription.txt','w',encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "            z.write('transcription.txt')\n",
    "        \n",
    "        if seo_text and os.path.exists(f\"{out_pref}_description.txt\"):\n",
    "            z.write(f\"{out_pref}_description.txt\")\n",
    "    \n",
    "    return zip_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎛️ CLI Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse command line arguments\"\"\"\n",
    "    p = argparse.ArgumentParser(description=\"AI Shorts Generator - CLI runner\")\n",
    "\n",
    "    src = p.add_mutually_exclusive_group(required=True)\n",
    "    src.add_argument(\"--youtube-url\", type=str, help=\"YouTube video URL to download and process\")\n",
    "    src.add_argument(\"--video-file\", type=str, help=\"Local video file path to process\")\n",
    "\n",
    "    p.add_argument(\"--srt-file\", type=str, help=\"Optional SRT file to skip transcription and use its timing/text\")\n",
    "\n",
    "    p.add_argument(\"--provider\", choices=[\"OpenAI\", \"Gemini\"], default=\"OpenAI\",\n",
    "                   help=\"LLM provider to use for highlight selection and title generation\")\n",
    "    p.add_argument(\"--openai-key\", type=str, default=os.getenv(\"OPENAI_API_KEY\", \"\"),\n",
    "                   help=\"OpenAI API key (fallback to env OPENAI_API_KEY)\")\n",
    "    p.add_argument(\"--gemini-key\", type=str, default=os.getenv(\"GEMINI_API_KEY\", \"\"),\n",
    "                   help=\"Gemini API key (fallback to env GEMINI_API_KEY)\")\n",
    "\n",
    "    p.add_argument(\"--min-len\", type=float, default=15, help=\"Minimum clip length (seconds)\")\n",
    "    p.add_argument(\"--max-len\", type=float, default=60, help=\"Maximum clip length (seconds)\")\n",
    "    p.add_argument(\"--max-clips\", type=int, default=5, help=\"Maximum number of clips to generate\")\n",
    "\n",
    "    p.add_argument(\"--aspect\", choices=[\"9:16\", \"16:9\", \"1:1\"], default=\"9:16\",\n",
    "                   help=\"Target aspect ratio for output clips\")\n",
    "    p.add_argument(\"--crop-mode\", choices=[\"Center\", \"Face-track\"], default=\"Center\",\n",
    "                   help=\"Cropping mode: simple center crop or face tracking where possible\")\n",
    "\n",
    "    p.add_argument(\"--karaoke\", action=\"store_true\", help=\"Burn karaoke-style subtitles into the clips\")\n",
    "    p.add_argument(\"--export-srt\", action=\"store_true\", help=\"Export per-clip SRT files alongside clips\")\n",
    "\n",
    "    p.add_argument(\"--title-mode\", choices=[\"Auto\", \"Custom\", \"None\"], default=\"Auto\",\n",
    "                   help=\"How to set titles for the clips\")\n",
    "    p.add_argument(\"--custom-title\", type=str, default=\"\", help=\"Custom title text if --title-mode=Custom\")\n",
    "    p.add_argument(\"--platform\", choices=[\"TikTok\", \"YouTube\", \"Instagram\"], default=\"TikTok\",\n",
    "                   help=\"Platform to adjust title overlay layout slightly\")\n",
    "\n",
    "    p.add_argument(\"--watermark\", type=str, help=\"Path to watermark/logo image to overlay\")\n",
    "\n",
    "    p.add_argument(\"--out-prefix\", type=str, default=\"short\", help=\"Prefix for output files\")\n",
    "\n",
    "    seo = p.add_mutually_exclusive_group(required=False)\n",
    "    seo.add_argument(\"--seo-text\", type=str, default=\"\", help=\"Optional SEO/description text to include in zip\")\n",
    "    seo.add_argument(\"--seo-text-file\", type=str, help=\"Path to a text file with SEO/description content\")\n",
    "\n",
    "    return p.parse_args()\n",
    "\n",
    "class NamedPath:\n",
    "    \"\"\"Lightweight wrapper to mimic Gradio's uploaded file objects\"\"\"\n",
    "    def __init__(self, path: Optional[str]):\n",
    "        self.name = path if path else ''\n",
    "\n",
    "def run_cli():\n",
    "    \"\"\"Run the CLI interface\"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    # Setup parameters\n",
    "    youtube_url = args.youtube_url or None\n",
    "    video_file = NamedPath(args.video_file) if args.video_file else None\n",
    "    srt_file = NamedPath(args.srt_file) if args.srt_file else None\n",
    "    watermark_file = NamedPath(args.watermark) if args.watermark else None\n",
    "\n",
    "    # Load SEO text from file if provided\n",
    "    seo_text = args.seo_text or \"\"\n",
    "    if args.seo_text_file and os.path.exists(args.seo_text_file):\n",
    "        try:\n",
    "            with open(args.seo_text_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                seo_text = f.read()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Run pipeline\n",
    "    zip_path = generate_pipeline(\n",
    "        youtube_url=youtube_url,\n",
    "        video_file=video_file,\n",
    "        srt_file=srt_file,\n",
    "        provider=args.provider,\n",
    "        openai_key=args.openai_key,\n",
    "        gemini_key=args.gemini_key,\n",
    "        min_len=args.min_len,\n",
    "        max_len=args.max_len,\n",
    "        max_clips=args.max_clips,\n",
    "        aspect=args.aspect,\n",
    "        crop_mode=args.crop_mode,\n",
    "        karaoke=args.karaoke,\n",
    "        export_srt=args.export_srt,\n",
    "        title_mode=args.title_mode,\n",
    "        custom_title=args.custom_title,\n",
    "        platform=args.platform,\n",
    "        out_prefix=args.out_prefix,\n",
    "        watermark_file=watermark_file,\n",
    "        seo_text=seo_text,\n",
    "        logger=print,\n",
    "    )\n",
    "\n",
    "    if zip_path:\n",
    "        print(f\"\\n✅ Success! Results saved to: {zip_path}\")\n",
    "    else:\n",
    "        print(\"\\n❌ Pipeline did not produce results. Check logs above for details.\")\n",
    "\n",
    "# Example CLI usage:\n",
    "# python AI_Shorts_Generator_Complete.ipynb --video-file your_video.mp4 --provider OpenAI --openai-key YOUR_KEY --min-len 15 --max-len 60 --max-clips 3 --aspect 9:16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌐 Gradio Web Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface():\n",
    "    \"\"\"Create Gradio web interface\"\"\"\n",
    "    \n",
    "    def run_gradio_ui(youtube_url, video_file, srt_file, provider, openai_key, gemini_key, \n",
    "                      target_len, tol, max_clips, aspect, crop_mode, karaoke, export_srt, \n",
    "                      title_mode, custom_title, platform, out_prefix, watermark_file, seo_text):\n",
    "        \"\"\"Gradio interface handler\"\"\"\n",
    "        logs_buf = []\n",
    "        \n",
    "        def log(m):\n",
    "            logs_buf.append(str(m))\n",
    "        \n",
    "        min_len = max(5, int(target_len) - int(tol))\n",
    "        max_len = int(target_len) + int(tol)\n",
    "        \n",
    "        try:\n",
    "            zip_path = generate_pipeline(\n",
    "                youtube_url, video_file, srt_file, provider, openai_key, gemini_key, \n",
    "                min_len, max_len, int(max_clips), aspect, crop_mode, bool(karaoke), \n",
    "                bool(export_srt), title_mode, custom_title, platform, out_prefix, \n",
    "                watermark_file, seo_text, logger=log\n",
    "            )\n",
    "            log('Done.' if zip_path else 'Failed to generate.')\n",
    "            return zip_path, '\\n'.join(logs_buf)\n",
    "        except Exception as ex:\n",
    "            log(f'Error: {ex}')\n",
    "            return None, '\\n'.join(logs_buf)\n",
    "    \n",
    "    # Create interface\n",
    "    with gr.Blocks(title=\"AI Shorts Generator\") as demo:\n",
    "        gr.Markdown(\"# 🎬 AI Shorts Generator - Complete Edition\")\n",
    "        gr.Markdown(\"Generate AI-powered short clips from long videos with both CLI and GUI interfaces.\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                youtube_url = gr.Textbox(label='YouTube URL (optional)', placeholder='https://www.youtube.com/watch?v=...')\n",
    "                video_file = gr.File(label='Or upload a video file', file_types=['video'])\n",
    "                srt_file = gr.File(label='Upload SRT subtitles (optional)', file_types=['.srt'])\n",
    "                \n",
    "                provider = gr.Dropdown(['OpenAI','Gemini'], label='AI Provider', value='OpenAI')\n",
    "                openai_key = gr.Textbox(label='OpenAI API Key', type='password', visible=True, \n",
    "                                      placeholder='sk-...')\n",
    "                gemini_key = gr.Textbox(label='Gemini API Key', type='password', visible=False,\n",
    "                                       placeholder='your-gemini-key')\n",
    "                \n",
    "                with gr.Row():\n",
    "                    target_len = gr.Slider(10, 120, value=60, step=1, label='Target short length (s)')\n",
    "                    tol = gr.Slider(2, 30, value=10, step=1, label='Length tolerance ± (s)')\n",
    "                max_clips = gr.Slider(1, 10, value=3, step=1, label='Maximum number of clips')\n",
    "                \n",
    "                aspect = gr.Dropdown(['9:16','16:9','1:1'], value='9:16', label='Aspect ratio')\n",
    "                crop_mode = gr.Dropdown(['Center','Face-track'], value='Face-track', label='Crop mode')\n",
    "                \n",
    "                with gr.Row():\n",
    "                    karaoke = gr.Checkbox(label='Burn karaoke subtitles', value=True)\n",
    "                    export_srt = gr.Checkbox(label='Export SRT files', value=True)\n",
    "                \n",
    "                title_mode = gr.Dropdown(['Auto','Custom','None'], value='Auto', label='Title overlay mode')\n",
    "                custom_title = gr.Textbox(label='Custom title (if Custom mode)', \n",
    "                                        placeholder='Enter your custom title...')\n",
    "                platform = gr.Dropdown(['TikTok','YouTube','Instagram'], value='TikTok', label='Platform')\n",
    "                \n",
    "                out_prefix = gr.Textbox(label='Output name prefix', value='short')\n",
    "                watermark_file = gr.File(label='Watermark image (optional)', file_types=['image'])\n",
    "                seo_text = gr.Textbox(label='SEO description (optional)', lines=3, \n",
    "                                    placeholder='Enter description for your clips...')\n",
    "                \n",
    "                go = gr.Button('🚀 Generate Shorts', variant='primary')\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                logs = gr.Textbox(label='Process logs', lines=20, interactive=False)\n",
    "                out_zip = gr.File(label='📦 Download Results ZIP')\n",
    "        \n",
    "        def toggle_provider(p):\n",
    "            return (gr.update(visible=p=='OpenAI'), gr.update(visible=p=='Gemini'))\n",
    "        \n",
    "        provider.change(toggle_provider, provider, [openai_key, gemini_key])\n",
    "        go.click(run_gradio_ui, \n",
    "                [youtube_url, video_file, srt_file, provider, openai_key, gemini_key, \n",
    "                 target_len, tol, max_clips, aspect, crop_mode, karaoke, export_srt, \n",
    "                 title_mode, custom_title, platform, out_prefix, watermark_file, seo_text], \n",
    "                [out_zip, logs])\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch Gradio interface\n",
    "print(\"🎯 Starting Gradio interface...\")\n",
    "print(\"📝 You can also use CLI with: python AI_Shorts_Generator_Complete.ipynb [arguments]\")\n",
    "\n",
    "# Uncomment to launch Gradio (will show public link in Colab)\n",
    "# demo = create_gradio_interface()\n",
    "# demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Usage Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 **Option 1: Gradio Web Interface (Easiest)**\n",
    "1. Uncomment the last 3 lines in the Gradio section above\n",
    "2. Run the cell\n",
    "3. Click the public link that appears\n",
    "4. Upload your video and configure settings\n",
    "5. Click \"Generate Shorts\" and download results\n",
    "\n",
    "### 💻 **Option 2: CLI Interface (Advanced)**\n",
    "```bash\n",
    "# Basic usage with local video\n",
    "python AI_Shorts_Generator_Complete.ipynb \\\n",
    "  --video-file your_video.mp4 \\\n",
    "  --provider OpenAI \\\n",
    "  --openai-key YOUR_OPENAI_KEY \\\n",
    "  --min-len 15 \\\n",
    "  --max-len 60 \\\n",
    "  --max-clips 3 \\\n",
    "  --aspect 9:16\n",
    "\n",
    "# With YouTube URL\n",
    "python AI_Shorts_Generator_Complete.ipynb \\\n",
    "  --youtube-url \"https://www.youtube.com/watch?v=...\" \\\n",
    "  --provider Gemini \\\n",
    "  --gemini-key YOUR_GEMINI_KEY \\\n",
    "  --karaoke \\\n",
    "  --export-srt\n",
    "```\n",
    "\n",
    "### ⚙️ **Configuration Options:**\n",
    "- **Video Input**: Upload file or provide YouTube URL\n",
    "- **AI Provider**: OpenAI (gpt-4o-mini) or Google Gemini (2.5-flash)\n",
    "- **Clip Length**: 10-120 seconds per clip\n",
    "- **Aspect Ratio**: 9:16 (TikTok), 16:9 (YouTube), 1:1 (Instagram)\n",
    "- **Crop Mode**: Center crop or face tracking\n",
    "- **Subtitles**: Optional karaoke-style burning\n",
    "- **Titles**: Auto-generated, custom, or none\n",
    "- **Watermark**: Optional logo overlay\n",
    "- **Export**: SRT files, transcription, SEO text\n",
    "\n",
    "### 🎬 **Output Includes:**\n",
    "- Multiple MP4 short clips\n",
    "- Per-clip SRT subtitle files (optional)\n",
    "- Full transcription text\n",
    "- SEO description (if provided)\n",
    "- All files in a ZIP download\n",
    "\n",
    "### 🔑 **API Keys Setup:**\n",
    "- **OpenAI**: Get from [platform.openai.com](https://platform.openai.com)\n",
    "- **Gemini**: Get from [aistudio.google.com](https://aistudio.google.com)\n",
    "- Keys are required for highlight detection and title generation\n",
    "\n",
    "**Ready to create amazing shorts! 🎬✨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
